{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2ab393b",
   "metadata": {},
   "source": [
    "# QuantityArray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff2e1db",
   "metadata": {},
   "source": [
    "## Review of a numpy series\n",
    "A typical numpy series actually wraps a kind of ExtensionArray (here called NumpyExtensionArray), which itself wraps an actual numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b83757a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s:\n",
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "5    5\n",
      "6    6\n",
      "7    7\n",
      "8    8\n",
      "9    9\n",
      "dtype: int64\n",
      "s.array:\n",
      "<NumpyExtensionArray>\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Length: 10, dtype: int64\n",
      "s.values:\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "s.to_numpy:\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "s = pd.Series(np.arange(10))\n",
    "print('s:')\n",
    "print(s)\n",
    "print(\"s.array:\")\n",
    "print(s.array) # the actual array backing a Series, will always be an ExtensionArray, a thin wrapper around one or more concrete arrays like a numpy.ndarray\n",
    "print(\"s.values:\")\n",
    "print(s.values) # Return Series as ndarray or ndarray-like depending on the dtype.\n",
    "print(\"s.to_numpy:\")\n",
    "print(s.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a446f72",
   "metadata": {},
   "source": [
    "## QuantityArray\n",
    "Physipandas defines a QuantityArray to represent Quantity in series. Again, a series that contains quantity wraps an ExtensionArray here QuantityArray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "356ea018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s:\n",
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "5    5\n",
      "6    6\n",
      "7    7\n",
      "8    8\n",
      "9    9\n",
      "dtype: physipy[m]\n",
      "s.array:\n",
      "INFO: default __repr__ handled by ExtensionArray:\\\\n<QuantityArray>\n",
      "[0 m, 1 m, 2 m, 3 m, 4 m, 5 m, 6 m, 7 m, 8 m, 9 m]\n",
      "Length: 10, dtype: physipy[m]\n",
      "s.values:\n",
      "INFO: default __repr__ handled by ExtensionArray:\\\\n<QuantityArray>\n",
      "[0 m, 1 m, 2 m, 3 m, 4 m, 5 m, 6 m, 7 m, 8 m, 9 m]\n",
      "Length: 10, dtype: physipy[m]\n",
      "s.to_numpy:\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(np.arange(10)*m, dtype='physipy[m]')\n",
    "print('s:')\n",
    "print(s)\n",
    "print(\"s.array:\")\n",
    "print(s.array) # the actual array backing a Series, will always be an ExtensionArray, a thin wrapper around one or more concrete arrays like a numpy.ndarray\n",
    "print(\"s.values:\")\n",
    "print(s.values) # Return Series as ndarray or ndarray-like depending on the dtype.\n",
    "print(\"s.to_numpy:\")\n",
    "print(s.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fdaf16",
   "metadata": {},
   "source": [
    "If a favunit is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8793d89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s:\n",
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "5    5\n",
      "6    6\n",
      "7    7\n",
      "8    8\n",
      "9    9\n",
      "dtype: physipy[m]\n",
      "s.array:\n",
      "INFO: default __repr__ handled by ExtensionArray:\\\\n<QuantityArray>\n",
      "[  0.0 km, 0.001 km, 0.002 km, 0.003 km, 0.004 km, 0.005 km, 0.006 km,\n",
      " 0.007 km, 0.008 km, 0.009 km]\n",
      "Length: 10, dtype: physipy[m]\n",
      "s.values:\n",
      "INFO: default __repr__ handled by ExtensionArray:\\\\n<QuantityArray>\n",
      "[  0.0 km, 0.001 km, 0.002 km, 0.003 km, 0.004 km, 0.005 km, 0.006 km,\n",
      " 0.007 km, 0.008 km, 0.009 km]\n",
      "Length: 10, dtype: physipy[m]\n",
      "s.to_numpy:\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "from physipy import units\n",
    "km = units['km']\n",
    "s = pd.Series((np.arange(10)*m).iinto(km), dtype='physipy[m]')\n",
    "print('s:')\n",
    "print(s)\n",
    "print(\"s.array:\")\n",
    "print(s.array) # the actual array backing a Series, will always be an ExtensionArray, a thin wrapper around one or more concrete arrays like a numpy.ndarray\n",
    "print(\"s.values:\")\n",
    "print(s.values) # Return Series as ndarray or ndarray-like depending on the dtype.\n",
    "print(\"s.to_numpy:\")\n",
    "print(s.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e2696d-d98e-4d4f-9759-8f8d9204237d",
   "metadata": {},
   "source": [
    "# Numpy support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e57bb47a-c82f-4989-9da0-3605635bf86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from physipandas import QuantityArray\n",
    "from physipy import m, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "181834ec-8616-4ace-b567-35b7249839ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(10)\n",
    "arrq = arr * m\n",
    "a = QuantityArray(arrq)\n",
    "b = QuantityArray(arrq, dtype=m)\n",
    "# Raises : GOOD c = QuantityArray(arrq, dtype=s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606995a6-51d4-47c4-b5d6-141d82cd7d2d",
   "metadata": {},
   "source": [
    "All of these are working properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f7e3057-59de-4c13-a4f0-cc5f275d234c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rb/tllkdnj94_5b7lb8tbrlg9240000gn/T/ipykernel_30597/3790816906.py:2: FutureWarning: pd.api.extensions.take accepting non-standard inputs is deprecated and will raise in a future version. Pass either a numpy.ndarray, ExtensionArray, Index, or Series instead.\n",
      "  take(b._data, [1,2,3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas.core.algorithms import take\n",
    "take(b._data, [1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3362b09a-faab-4ba1-b0b4-9eaa3326a015",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mocquin/Documents/CLE/Optique/Python/JUPYTER/MYLIB10/MODULES/physipy/physipy/quantity/quantity.py:209: RuntimeWarning: divide by zero encountered in divide\n",
      "  return type(self)(self.value / y.value,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(a)\n",
    "np.abs(a)\n",
    "np.prod(a)\n",
    "np.hypot(a, a)\n",
    "np.trapz(a)\n",
    "np.mean(a)\n",
    "np.sort(a)\n",
    "a+1*m\n",
    "a+np.arange(10)*m\n",
    "a+a\n",
    "2*a\n",
    "a*2\n",
    "a**2\n",
    "a/2\n",
    "2/a\n",
    "a**0.5\n",
    "a[0]\n",
    "a[0:2]\n",
    "#print(a.iloc[0:3])\n",
    "any(a)\n",
    "all(a)\n",
    "# print(sum(a)) # start init value dimension error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fd24b0-9be3-4030-adf8-d06b9f2bffc4",
   "metadata": {},
   "source": [
    "# QuantityArray performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8943a194-ad82-400f-8bc8-bc16fd58fc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from physipandas import QuantityArray\n",
    "from physipy import m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "993037dd-ead0-4c45-a451-ffd40011e443",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(10)\n",
    "arrq = arr * m\n",
    "arrqar = QuantityArray(arrq)\n",
    "arrnps = pd.Series(arr)\n",
    "arrs = pd.Series(QuantityArray(arrq), dtype=\"physipy[m]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed1488c8-86f0-4962-9fb7-0eb4d117a25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19 µs ± 31.6 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n",
      "9.24 µs ± 28.6 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "401 µs ± 45.6 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "63.6 µs ± 329 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "486 µs ± 15.3 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.sqrt(arr)\n",
    "%timeit np.sqrt(arrq)\n",
    "%timeit np.sqrt(arrqar)\n",
    "%timeit np.sqrt(arrnps)\n",
    "%timeit np.sqrt(arrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29656b61-7459-4872-99bc-52fc0c7e7886",
   "metadata": {},
   "source": [
    "- PintArray : https://github.com/hgrecco/pint-pandas/blob/cf527e48557a1e028c6f2d4e628aa7a6cd1b30d4/pint_pandas/pint_array.py#L181"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ade604e-f0df-4024-a6f1-19cd46bb1706",
   "metadata": {},
   "source": [
    "- Pandas ExtensionArray : https://pandas.pydata.org/docs/reference/api/pandas.api.extensions.ExtensionArray.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc2f071-9880-42ba-88f9-cc34ae935d29",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a0ec2c-2c50-4a32-8288-899128a75e0e",
   "metadata": {},
   "source": [
    "Attributes\n",
    " - dtype : An instance of 'ExtensionDtype', to define as a property\n",
    " - nbytes : The number of bytes needed to store this object in memory. Return an int\n",
    " - ndim : \n",
    " - shape : \n",
    " \n",
    " \n",
    "Methods : \n",
    " - _from_sequence : Construct a new ExtensionArray from a sequence of scalars.\n",
    " - __getitem__ : For scalar ``item``, return a scalar value suitable for the array's type. This should be an instance of ``self.dtype.type``. For slice ``key``, return an instance of ``ExtensionArray``, even if the slice is length 0 or 1. For a boolean mask, return an instance of ``ExtensionArray``, filtered to the values where ``item`` is True.\n",
    " - __len__ : len of this array\n",
    " - __eq__ : this should return a boolean numpy ndarray or a boolean ExtensionArray. When `other` is one of Series, Index, or DataFrame, this method should return  otImplemented (to ensure that those objects are responsible for first unpacking the arrays, and then dispatch the operation to the underlying arrays)\n",
    " - isna : A 1-D array indicating if each value is missing. In most cases, this should return a NumPy ndarray\n",
    " - take : called by ``Series.__getitem__``, ``.loc``, ``iloc``, when `indices` is a sequence of values. Should return another ExtensionArray instance, with dtype of corresponding Dtype. if allow_fill and fill_value is None: fill_value = self.dtype.na_value (here, self.dtype.na_value is the nan value of the corresponding Dtype)\n",
    " - copy : such that self.copy() returns a copy of the ExtensionArray. Should use a copy of the base data, and same Dtype\n",
    " - _concatenate_same_type : Concatenate multiple array of this dtype. Basically convert a list of ExtentionArray of the same Dtype to a single concatenated ExtensionArray of the same Dtype\n",
    " \n",
    "Second : \n",
    " - _reduce \n",
    " - dropna : \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1054b1-c6c2-49fb-a1b7-691295d944fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@property\n",
    "def dtype(self) -> ExtensionDtype:\n",
    "    \"\"\"\n",
    "    An instance of 'ExtensionDtype'.\n",
    "    \"\"\"\n",
    "    raise AbstractMethodError(self)\n",
    "    \n",
    "@property\n",
    "def nbytes(self) -> int:\n",
    "    \"\"\"\n",
    "    The number of bytes needed to store this object in memory.\n",
    "    \"\"\"\n",
    "    # If this is expensive to compute, return an approximate lower bound\n",
    "    # on the number of bytes needed.\n",
    "    raise AbstractMethodError(self)\n",
    "    \n",
    "def isna(self) -> np.ndarray | ExtensionArraySupportsAnyAll:\n",
    "    \"\"\"\n",
    "    A 1-D array indicating if each value is missing.\n",
    "    Returns\n",
    "    -------\n",
    "    na_values : Union[np.ndarray, ExtensionArray]\n",
    "        In most cases, this should return a NumPy ndarray. For\n",
    "        exceptional cases like ``SparseArray``, where returning\n",
    "        an ndarray would be expensive, an ExtensionArray may be\n",
    "        returned.\n",
    "    Notes\n",
    "    -----\n",
    "    If returning an ExtensionArray, then\n",
    "    * ``na_values._is_boolean`` should be True\n",
    "    * `na_values` should implement :func:`ExtensionArray._reduce`\n",
    "    * ``na_values.any`` and ``na_values.all`` should be implemented\n",
    "    \"\"\"\n",
    "    raise AbstractMethodError(self)\n",
    "\n",
    "def take(\n",
    "    self: ExtensionArrayT,\n",
    "    indices: Sequence[int],\n",
    "    *,\n",
    "    allow_fill: bool = False,\n",
    "    fill_value: Any = None,\n",
    ") -> ExtensionArrayT:\n",
    "    \"\"\"\n",
    "    Take elements from an array.\n",
    "    Parameters\n",
    "    ----------\n",
    "    indices : sequence of int\n",
    "        Indices to be taken.\n",
    "    allow_fill : bool, default False\n",
    "        How to handle negative values in `indices`.\n",
    "        * False: negative values in `indices` indicate positional indices\n",
    "          from the right (the default). This is similar to\n",
    "          :func:`numpy.take`.\n",
    "        * True: negative values in `indices` indicate\n",
    "          missing values. These values are set to `fill_value`. Any other\n",
    "          other negative values raise a ``ValueError``.\n",
    "    fill_value : any, optional\n",
    "        Fill value to use for NA-indices when `allow_fill` is True.\n",
    "        This may be ``None``, in which case the default NA value for\n",
    "        the type, ``self.dtype.na_value``, is used.\n",
    "        For many ExtensionArrays, there will be two representations of\n",
    "        `fill_value`: a user-facing \"boxed\" scalar, and a low-level\n",
    "        physical NA value. `fill_value` should be the user-facing version,\n",
    "        and the implementation should handle translating that to the\n",
    "        physical version for processing the take if necessary.\n",
    "    Returns\n",
    "    -------\n",
    "    ExtensionArray\n",
    "    Raises\n",
    "    ------\n",
    "    IndexError\n",
    "        When the indices are out of bounds for the array.\n",
    "    ValueError\n",
    "        When `indices` contains negative values other than ``-1``\n",
    "        and `allow_fill` is True.\n",
    "    See Also\n",
    "    --------\n",
    "    numpy.take : Take elements from an array along an axis.\n",
    "    api.extensions.take : Take elements from an array.\n",
    "    Notes\n",
    "    -----\n",
    "    ExtensionArray.take is called by ``Series.__getitem__``, ``.loc``,\n",
    "    ``iloc``, when `indices` is a sequence of values. Additionally,\n",
    "    it's called by :meth:`Series.reindex`, or any other method\n",
    "    that causes realignment, with a `fill_value`.\n",
    "    Examples\n",
    "    --------\n",
    "    Here's an example implementation, which relies on casting the\n",
    "    extension array to object dtype. This uses the helper method\n",
    "    :func:`pandas.api.extensions.take`.\n",
    "    .. code-block:: python\n",
    "       def take(self, indices, allow_fill=False, fill_value=None):\n",
    "           from pandas.core.algorithms import take\n",
    "           # If the ExtensionArray is backed by an ndarray, then\n",
    "           # just pass that here instead of coercing to object.\n",
    "           data = self.astype(object)\n",
    "           if allow_fill and fill_value is None:\n",
    "               fill_value = self.dtype.na_value\n",
    "           # fill value should always be translated from the scalar\n",
    "           # type for the array, to the physical storage type for\n",
    "           # the data, before passing to take.\n",
    "           result = take(data, indices, fill_value=fill_value,\n",
    "                         allow_fill=allow_fill)\n",
    "           return self._from_sequence(result, dtype=self.dtype)\n",
    "    \"\"\"\n",
    "    # Implementer note: The `fill_value` parameter should be a user-facing\n",
    "    # value, an instance of self.dtype.type. When passed `fill_value=None`,\n",
    "    # the default of `self.dtype.na_value` should be used.\n",
    "    # This may differ from the physical storage type your ExtensionArray\n",
    "    # uses. In this case, your implementation is responsible for casting\n",
    "    # the user-facing type to the storage type, before using\n",
    "    # pandas.api.extensions.take\n",
    "    raise AbstractMethodError(self)\n",
    "\n",
    "    # Base Pandas implementation example\n",
    "    # from pandas.core.algorithms import take\n",
    "    # # If the ExtensionArray is backed by an ndarray, then\n",
    "    # # just pass that here instead of coercing to object.\n",
    "    # data = self.astype(object)\n",
    "    # if allow_fill and fill_value is None:\n",
    "    #     fill_value = self.dtype.na_value\n",
    "    # # fill value should always be translated from the scalar\n",
    "    # # type for the array, to the physical storage type for\n",
    "    # # the data, before passing to take.\n",
    "    # result = take(data, indices, fill_value=fill_value,\n",
    "    #               allow_fill=allow_fill)\n",
    "    # return self._from_sequence(result, dtype=self.dtype)\n",
    "    #\n",
    "    # Pintpandas implementation\n",
    "    # data = self._data\n",
    "    # if allow_fill and fill_value is None:\n",
    "    #     fill_value = self.dtype.na_value\n",
    "    # if isinstance(fill_value, _Quantity):\n",
    "    #     fill_value = fill_value.to(self.units).magnitude\n",
    "    # result = take(data, indices, fill_value=fill_value, allow_fill=allow_fill)\n",
    "    # return PintArray(result, dtype=self.dtype)\n",
    "\n",
    "    def copy(self: ExtensionArrayT) -> ExtensionArrayT:\n",
    "        \"\"\"\n",
    "        Return a copy of the array.\n",
    "        Returns\n",
    "        -------\n",
    "        ExtensionArray\n",
    "        \"\"\"\n",
    "        raise AbstractMethodError(self)\n",
    "        \n",
    "    # Pintpandas implementation\n",
    "    # def copy(self, deep=False):\n",
    "    # data = self._data\n",
    "    # if deep:\n",
    "    #     data = copy.deepcopy(data)\n",
    "    # else:\n",
    "    #     data = data.copy()\n",
    "    # return type(self)(data, dtype=self.dtype)\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def _concat_same_type(\n",
    "        cls: type[ExtensionArrayT], to_concat: Sequence[ExtensionArrayT]\n",
    "    ) -> ExtensionArrayT:\n",
    "        \"\"\"\n",
    "        Concatenate multiple array of this dtype.\n",
    "        Parameters\n",
    "        ----------\n",
    "        to_concat : sequence of this type\n",
    "        Returns\n",
    "        -------\n",
    "        ExtensionArray\n",
    "        \"\"\"\n",
    "        # Implementer note: this method will only be called with a sequence of\n",
    "        # ExtensionArrays of this class and with the same dtype as self. This\n",
    "        # should allow \"easy\" concatenation (no upcasting needed), and result\n",
    "        # in a new ExtensionArray of the same dtype.\n",
    "        # Note: this strict behaviour is only guaranteed starting with pandas 1.1\n",
    "        raise AbstractMethodError(cls)\n",
    "        \n",
    "    # Pintpandas implementation\n",
    "    # @classmethod\n",
    "    # def _concat_same_type(cls, to_concat):\n",
    "    #     output_units = to_concat[0].units\n",
    "\n",
    "    #     data = []\n",
    "    #     for a in to_concat:\n",
    "    #         converted_values = a.quantity.to(output_units).magnitude\n",
    "    #         data.append(np.atleast_1d(converted_values))\n",
    "\n",
    "    #     return cls(np.concatenate(data), output_units)\n",
    "    \n",
    "def __eq__(self, other: Any) -> ArrayLike:  # type: ignore[override]\n",
    "        \"\"\"\n",
    "        Return for `self == other` (element-wise equality).\n",
    "        \"\"\"\n",
    "        # Implementer note: this should return a boolean numpy ndarray or\n",
    "        # a boolean ExtensionArray.\n",
    "        # When `other` is one of Series, Index, or DataFrame, this method should\n",
    "        # return NotImplemented (to ensure that those objects are responsible for\n",
    "        # first unpacking the arrays, and then dispatch the operation to the\n",
    "        # underlying arrays)\n",
    "        raise AbstractMethodError(self)\n",
    "        \n",
    "def __len__(self) -> int:\n",
    "    \"\"\"\n",
    "    Length of this array\n",
    "    Returns\n",
    "    -------\n",
    "    length : int\n",
    "    \"\"\"\n",
    "    raise AbstractMethodError(self)\n",
    "\n",
    "# pintpandas implementation\n",
    "# def __len__(self):\n",
    "# # type: () -> int\n",
    "# \"\"\"Length of this array\n",
    "# Returns\n",
    "# -------\n",
    "# length : int\n",
    "# \"\"\"\n",
    "# return len(self._data)\n",
    "\n",
    "    def __getitem__(self, item: PositionalIndexer) -> ExtensionArray | Any:\n",
    "        \"\"\"\n",
    "        Select a subset of self.\n",
    "        Parameters\n",
    "        ----------\n",
    "        item : int, slice, or ndarray\n",
    "            * int: The position in 'self' to get.\n",
    "            * slice: A slice object, where 'start', 'stop', and 'step' are\n",
    "              integers or None\n",
    "            * ndarray: A 1-d boolean NumPy ndarray the same length as 'self'\n",
    "        Returns\n",
    "        -------\n",
    "        item : scalar or ExtensionArray\n",
    "        Notes\n",
    "        -----\n",
    "        For scalar ``item``, return a scalar value suitable for the array's\n",
    "        type. This should be an instance of ``self.dtype.type``.\n",
    "        For slice ``key``, return an instance of ``ExtensionArray``, even\n",
    "        if the slice is length 0 or 1.\n",
    "        For a boolean mask, return an instance of ``ExtensionArray``, filtered\n",
    "        to the values where ``item`` is True.\n",
    "        \"\"\"\n",
    "        raise AbstractMethodError(self)\n",
    "        \n",
    "# if is_integer(item):\n",
    "#     return self._data[item] * self.units\n",
    "# \n",
    "# item = check_array_indexer(self, item)\n",
    "# \n",
    "# return self.__class__(self._data[item], self.dtype)\n",
    "\n",
    "# @classmethod\n",
    "# def _from_sequence(cls, scalars, *, dtype: Dtype | None = None, copy=False):\n",
    "#     \"\"\"\n",
    "#     Construct a new ExtensionArray from a sequence of scalars.\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     scalars : Sequence\n",
    "#         Each element will be an instance of the scalar type for this\n",
    "#         array, ``cls.dtype.type`` or be converted into this type in this method.\n",
    "#     dtype : dtype, optional\n",
    "#         Construct for this particular dtype. This should be a Dtype\n",
    "#         compatible with the ExtensionArray.\n",
    "#     copy : bool, default False\n",
    "#         If True, copy the underlying data.\n",
    "#     Returns\n",
    "#     -------\n",
    "#     ExtensionArray\n",
    "#     \"\"\"\n",
    "#     raise AbstractMethodError(cls)\n",
    "\n",
    "# @classmethod\n",
    "# def _from_sequence(cls, scalars, dtype=None, copy=False):\n",
    "#     \"\"\"\n",
    "#     Initialises a PintArray from a list like of quantity scalars or a list like of floats and dtype\n",
    "#     -----\n",
    "#     Usage\n",
    "#     PintArray._from_sequence([Q_(1,\"m\"),Q_(2,\"m\")])\n",
    "#     \"\"\"\n",
    "#     master_scalar = None\n",
    "#     try:\n",
    "#         master_scalar = next(i for i in scalars if hasattr(i, \"units\"))\n",
    "#     except StopIteration:\n",
    "#         if isinstance(scalars, PintArray):\n",
    "#             dtype = scalars._dtype\n",
    "#         if dtype is None:\n",
    "#             raise ValueError(\n",
    "#                 \"Cannot infer dtype. No dtype specified and empty array\"\n",
    "#             )\n",
    "#     if dtype is None and not isinstance(master_scalar, _Quantity):\n",
    "#         raise ValueError(\"No dtype specified and not a sequence of quantities\")\n",
    "#     if dtype is None and isinstance(master_scalar, _Quantity):\n",
    "#         dtype = PintType(master_scalar.units)\n",
    "\n",
    "#     def quantify_nan(item):\n",
    "#         if type(item) is float:\n",
    "#             return item * dtype.units\n",
    "#         return item\n",
    "\n",
    "#     if isinstance(master_scalar, _Quantity):\n",
    "#         scalars = [quantify_nan(item) for item in scalars]\n",
    "#         scalars = [item.to(dtype.units).magnitude for item in scalars]\n",
    "#     return cls(scalars, dtype=dtype, copy=copy)\n",
    "\n",
    "    def _reduce(self, name: str, *, skipna: bool = True, **kwargs):\n",
    "        \"\"\"\n",
    "        Return a scalar result of performing the reduction operation.\n",
    "        Parameters\n",
    "        ----------\n",
    "        name : str\n",
    "            Name of the function, supported values are:\n",
    "            { any, all, min, max, sum, mean, median, prod,\n",
    "            std, var, sem, kurt, skew }.\n",
    "        skipna : bool, default True\n",
    "            If True, skip NaN values.\n",
    "        **kwargs\n",
    "            Additional keyword arguments passed to the reduction function.\n",
    "            Currently, `ddof` is the only supported kwarg.\n",
    "        Returns\n",
    "        -------\n",
    "        scalar\n",
    "        Raises\n",
    "        ------\n",
    "        TypeError : subclass does not define reductions\n",
    "        \"\"\"\n",
    "        raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\n",
    "\n",
    "    def _reduce(self, name, skipna=True, **kwds):\n",
    "        \"\"\"\n",
    "        Return a scalar result of performing the reduction operation.\n",
    "        Parameters\n",
    "        ----------\n",
    "        name : str\n",
    "            Name of the function, supported values are:\n",
    "            { any, all, min, max, sum, mean, median, prod,\n",
    "            std, var, sem, kurt, skew }.\n",
    "        skipna : bool, default True\n",
    "            If True, skip NaN values.\n",
    "        **kwargs\n",
    "            Additional keyword arguments passed to the reduction function.\n",
    "            Currently, `ddof` is the only supported kwarg.\n",
    "        Returns\n",
    "        -------\n",
    "        scalar\n",
    "        Raises\n",
    "        ------\n",
    "        TypeError : subclass does not define reductions\n",
    "        \"\"\"\n",
    "        functions = {\n",
    "            \"all\": all,\n",
    "            \"any\": any,\n",
    "            \"min\": min,\n",
    "            \"max\": max,\n",
    "            \"sum\": sum,\n",
    "            \"mean\": np.mean,\n",
    "            \"median\": np.median,\n",
    "        }\n",
    "        if name not in functions:\n",
    "            raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\n",
    "\n",
    "        if skipna:\n",
    "            quantity = self.dropna().quantity\n",
    "        else:\n",
    "            quantity = self.quantity\n",
    "\n",
    "        return functions[name](quantity)\n",
    "    \n",
    "        def dropna(self):\n",
    "        \"\"\"\n",
    "        Return ExtensionArray without NA values.\n",
    "        Returns\n",
    "        -------\n",
    "        valid : ExtensionArray\n",
    "        \"\"\"\n",
    "        # error: Unsupported operand type for ~ (\"ExtensionArray\")\n",
    "        return self[~self.isna()]  # type: ignore[operator]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
